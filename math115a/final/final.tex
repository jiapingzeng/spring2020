\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amssymb}

\title{Math 115A Final}
\author{Jiaping Zeng}
\date{6/9/2020}

\begin{document}
\setstretch{1.35}

\begin{itemize}
	\item [1.]
	      \begin{itemize}
		      \item [(a)] $V$ is the space of polynomials of degree up to 3 such that the coefficients of its terms combine to 0; i.e. an arbitrary vector in $V$ would look like $p(x)=ax+bx^2+cx^3-(a+b+c)=a(x-1)+b(x^2-1)+c(x^3-1)$. Then, $\beta=\{x-1,x^2-1,x^3-1\}$ is a basis of $V$.
		      \item [(b)] $T(x-1)=x-1$\\$T(x^2-1)=x^2+2x-3=2(x-1)+(x^2-1)$\\$T(x^3-1)=x^3+6x^2-6x-1=-6(x-1)+6(x^2-1)+(x^3-1)$\[\implies[T]_\beta=\begin{pmatrix}
				            1 & 2 & -6 \\0&1&6\\0&0&1
			            \end{pmatrix}\]\[\implies P_T(\lambda)=\text{det}(T-\lambda I)=(1-\lambda)^3\]
		      \item [(c)] $T$ has a single eigenvalue $\lambda=1$ with algebraic multiplicity $3$.
		      \item [(d)] $T(v)=1v$\[\implies\begin{pmatrix}1&2&-6\\0&1&6\\0&0&1\end{pmatrix}\begin{pmatrix}a\\b\\c\end{pmatrix}=\begin{pmatrix}a\\b\\c\end{pmatrix}\]\[\begin{pmatrix}
				            a+2b-6c \\b+6c\\c
			            \end{pmatrix}=\begin{pmatrix}
				            a \\b\\c
			            \end{pmatrix}\]\[\implies b=c=0\]Then $x-1$ is an eigenvector for $\lambda=1$.
		      \item [(e)] $T$ is not diagonalisable as its algebraic multiplicity and geometric multiplicity ($\text{nullity}(T-Id)=1$) does not match for $\lambda=1$.
	      \end{itemize}
\end{itemize}

\newpage

\begin{itemize}
	\item [2.]
	      \begin{itemize}
		      \item [(a)] Let $C=\{P,Q,R\}$. Then, \[P=H\]\[Q=K-\dfrac{\langle K,P\rangle}{||P||^2}P=K-\dfrac{2}{2}P=\begin{pmatrix}0&1\\0&0\end{pmatrix}\]\[R=L-\dfrac{\langle L,P\rangle}{||P||^2}P-\dfrac{\langle L,Q\rangle}{||Q||^2}Q=L-\dfrac{2}{2}P-\dfrac{1}{0}Q\]
		      \item [(b)] $\langle T(Id),E\rangle=\langle Id,T^*(E)\rangle$
		      \item [(c)]
	      \end{itemize}
\end{itemize}

\newpage

\begin{itemize}
	\item [3.]
	      \begin{itemize}
			  \item [(a)] 
			  To show that $W'$ is also an $X$-subspace, it suffices to show that $\langle X(u),w\rangle+\langle X(X(u)),X(w)\rangle=0$ for $u\in W'$. We can simplify the above expression as follows:\\$\langle X(u),w\rangle+\langle X(X(u)),X(w)\rangle$\\$=\langle X(u),w\rangle+\langle X^2(u),X(w)\rangle$\\$=\langle X(u),w\rangle+\langle u,X(w)\rangle$
		      \item [(b)] Let $u,v,w\in V$ and $a\in\mathbb{F}$. Then we can verify the definiton of inner product as follows:
		            \begin{itemize}
			            \item [(i)] $\langle u,v\rangle_X$\\$=\langle u,v\rangle+\langle X(u),X(v)\rangle$\\$=\overline{\langle v,u\rangle}+\overline{\langle X(u),X(v)\rangle}$\\$=\overline{\langle v,u\rangle}_X$
			            \item [(ii)] $\langle au,v\rangle_X$\\$=\langle au,v\rangle+\langle X(au),X(v)\rangle$\\$=a\langle u,v\rangle+a\langle X(u),X(v)\rangle$\\$=a(\langle u,v\rangle+\langle X(u),X(v)\rangle)$\\$=a\langle u,v\rangle_X$
			            \item [(iii)] $\langle u+v,w\rangle_X$\\$=\langle u+v,w\rangle+\langle X(u+v),X(w)\rangle$\\$=(\langle u,w\rangle+\langle v,w\rangle)+(\langle X(u),X(w)\rangle+\langle X(v),X(w)\rangle)$\\$=(\langle u,w\rangle+\langle X(u),X(w)\rangle)+(\langle v,w\rangle+\langle X(v),X(w)\rangle)$\\$=\langle u,w\rangle_X+\langle v,w\rangle_X$
			            \item [(iv)] $\langle v,v\rangle_X=\langle v,v\rangle+\langle X(v),X(v)\rangle$ by definiton. If $v\neq 0$, then $\langle v,v\rangle>0$. In addition, $\langle X(v),X(v)\rangle\geq 0$ even if $X(v)=0$. Then, $\langle v,v\rangle_X>0$ for nonzero $v\in V$.
		            \end{itemize}
		      \item [(c)] To be proved
		      \item [(d)]
	      \end{itemize}
\end{itemize}

\newpage

\begin{itemize}
	\item [4.]
	      \begin{itemize}
			  \item [(a)] To be proved: $T$ is an isomorphism $\Leftrightarrow T(B)$ is a basis for $W$:
			  \begin{itemize}
				  \item [$\Rightarrow$:] 
				  \item [$\Leftarrow$:] 
			  \end{itemize}
		      \item [(b)]
		      \item [(c)]
	      \end{itemize}
\end{itemize}

\newpage

\begin{itemize}
	\item [5.]
	      \begin{itemize}
		      \item [(a)] Let $\lambda$ be an eigenvalue of $T$, i.e. $T(v)=\lambda v$ for some $v\in V$. Then, $T^2(v)=T(T(v))=T(\lambda v)=\lambda T(v)=\lambda^2v$. By definition of \textit{projpotent}, $T(v)=T^2(v)$. Then $\lambda v=\lambda^2 v \implies \lambda=\lambda^2$. Therefore $0$ and $1$ are the only possible eigenvalues.
		      \item [(b)]
			  \item [(c)] Let $n=\text{dim}V$. Since $T$ is diagonalisable, there exists an eigenbasis $\beta=\{u_1,\ldots,u_n\}$ for $T$ such that $[T]_\beta^\beta$ is diagonal with corresponding eigenvalues on the main diagonal. As shown in $(a)$, $T$ can only have eigenvalues of $0$ or $1$. Now let $k$ be the number of zero entries on the main diagonal, which corresponds to eigenvectors $u_1,\ldots,u_k$ upon renumbering. Then for each $u_i, 1\geq i\geq k$, $T(u_i)=0u_i=0$, i.e. $\text{nullity}(T)=k$ and $\text{rank}(T)=n-k$. In addition, since $[T]$ is $n\times n$ diagonal matrix, the number of nonzero entries on its diagonal is $n-k$. Again as shown in $(a)$, the only nonzero eigenvalue $T$ can have is $1$. Then $\text{tr}(T)=1(n-k)=n-k=\text{rank}(T)$.
	      \end{itemize}
\end{itemize}

\end{document}